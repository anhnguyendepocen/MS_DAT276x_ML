[
["index.html", "Principle of Machine Learning About this notebook Course Overview Lab Overview", " Principle of Machine Learning About this notebook This is my notes and solutions to lab on the course DAT276x Principle of Machine Learning: R Edition Course Overview 1. Introduction to Machine Learning High Level Data Science Process High Level Process Overview of Machine Learning with K-Means Classifiers Overview of Machine Learning with K-Means Classifiers Demo of K-Means Classification 2. Exploring Data Exploratory Data Analysis for Regression Data Exploration Data Visualization Visualizing Distributions Visualizing Data Relationships Visualizing Categorical Relationships Using Aesthetics to Visualize High Dimensions Visualizing High Dimensional Relationships Exploratory Data Analysis for Classification Visualizing for Classification Frequency Tables 3. Cleaning and Preparing Data Data Preparation and Cleaning Data Preparation Duplicates Missing Values Errors and Outliers Scaling Splitting Summary Finding and Treating Missing Data Finding and Treating Duplicates Scaling Data Feature Engineering Overview of Feature Engineering Transforming Features Interaction Terms Summary Feature Engineering 4. Getting Started with Supervised Learning Regression Introduction to Linear Regression Multiple Linear Regression Basics of ML with R Evaluating Regression Models Demo of Evaluating Regression Models with Categorical Variables Classification Introduction to Classification Loss Function for Classification Statistical Learning Theory for Supervised Learning Logistic Regression Maximum Likelihood Perspective Evaluating Classifiers ROC Curves ROC Curve Algorithms Classification Models Demo of Classifier Evaluation Imbalanced Data Approaches for Addressing Imbalanced Data 5. Improving Model Performance Principles of Model Improvement Improving Models Regularization Performing Regularization Interpreting Features Features Selection Techniques for Improving Models Sweeping Parameters Cross Validation Nested Cross Validation Model Selection and Cross Validation Dimensionality Reduction Overview of Dimensionality Reduction Principal Component Analysis 6. Machine Learning Algorithms Introduction to Decision Trees Decision Trees What is Information Ensemble Methods Boosting AdaBoost Coordinate Descent Decision Forests Neural Networks Introduction to Neural Networks Backpropagation Support Vector Machines (SVMs) Introduction to SVMs Kernels for SVMs Bayes Theorem Theory of Naive Bayes Models 7. Unsupervised Learning Clustering Introduction to Clustering K-Means Clustering Hierachical Clustering Evaluating Clustering Models 8 Final Exam Introduction About the Data Data Exploration Challenge 2: Classification Classification - Grading Challenge 3: Regression Regression Grading Lab Overview This course includes labs that you can use to gain hands-on experience of building data science solutions. The labs are graded, and you will be required to answer questions after each lab to verify that you have completed them successfully. Programming Languages Used in this Course Many of the labs involve writing code in R. This course does not attempt to teach you exhaustive programming skills and syntax in these languages, so any experience you may already have in either language will be useful. However, the labs and demonstrations will provide you with the code you need to perform the data science operations described in this course, even if you have no prior experience, and there are references to resources that will help you work with these languages. Platform Requirements To execute the labs for this course you will need a computer meeting the following minimum requirements At least 10GB of free disk space. At least 8 GB of RAM. Running Windows, MAC OS X, or Linux. Installing Software for the Labs If you do not already have an environment capable of running a Jupyter notebook with an R kernel, follow the steps below. Anaconda stack: Installing Anaconda is one of the easiest ways to install Jupyter notebooks. Download the Python 3.X version for your operating system from the Anaconda download page. R: Download and install the latest version of R from the Comprehensive R Archive Network Jupyter R Kernel: In order to run R in Jupyter you must download the Jupyter IRkernel. Follow the directions carefully. You can run a simple R session required for this installation by starting R and using the console. If this is the first time you have installed R you will need to run the command options(repos = “https://CRAN.R-project.org”) before you can install R packages, including the IRKernel. Important note for MAC users Note the warning that you must run the commands in step 2 in a command console, not from R Lab Materials From the Course Repository: You can download the Zip file with the course lab materials from the course Github repository. Click on the Clone or download tab, and selected Download Zip. If you have Git installed, you can clone this repository. Install R packages: You can install the R packages you will require for the labs by executing the code in the Setup notebook. Note: If you experience continual Jupyter kernel restarts, you may need to reinstall the R Rcpp package by executing the install.packages(“Rcpp”) command from the R console "],
["introduction-to-machine-learning.html", "1 Introduction to Machine Learning High Level Data Science Process 1.1 Overview of Machine Learning with K-Means Classifiers", " 1 Introduction to Machine Learning High Level Data Science Process Overview Historical Notes on KDD, CRISP-DM, Big Data and Data Science and their relationship to Data Mining and Machine Learning Example of the knowledge discovery process Historical Note Term “Big Data” coined by astronomers Cox and Ellsworth in 1997 KDD (Knowledge Discovery in Databases) Process Figure 1.1: Based on content in From Data Mining to Knowledge Discovery Cross Industry Standard Process for Data Mining (CRISP-DM) The stages are basically the same no matter who invents or reinvents the (Knowledge discovery / data mining /big data / data science) process. You may not always need all the stages. Data science is an iterative process. - Backwards arrows on most process diagrams. 1.0.1 Example of the knowledge discovery process I’ll walk you through the knowledge discovery process with an example - the process of predicting power failures in Manhattan. Motivation for Example In NYC the peak demand for electricity is rising. The infrastructure dates back to the 1880’s from the time of Thomas Edison. Power failures occur fairly often (enough to do statistic) and are expensive to repair We want to determine how to prioritize manhole inspections in order to reduce the number of manhole events (fires, explosions, outages) in the future. This is a real problem. Stagse in the knowledge discovery procss Opportunity Assessment &amp; Business Understanding Data Understanding &amp; Data Acquisition Data Preparation, including Cleaning and Transformation Model Building Policy Construciton Evaluation, Residuals and Metrics Model Deployment, Monitoring, Model Updates Opportunity Assessment &amp; Business Understanding What do you really want to accomplish and what are the constraints? What are the risks? How will you evaluate the quality of the results? For manhole events the general goal was to “Predict manhole fires and explosions before they occur.” We made it ore precise: Goal 1: Assess predictive accuracy for predicting manhole events in the uear before they happen. Goal 2: Create a cost-benefit analysis for inspection policies that takes into account the cost of inspections and manhole fires. Determine how often manholes need to be inspected. Data Understanding &amp; Data Acquisition Data were: Trouble tickets - free text documents typed by dispatchers documenting problems on the electrical grid. Records of information about manholes Records of information about underground cables Electrical shock information tables Extra information about serious events Inspection reports Vented cover data Data Preparation, including Cleaning and Transformation Sometimes 99% of the work. Turn free text into sturctured information: Trouble tickets turned into a vector like: Serious / Less Serious / Not an Event Year Month Day Manholes involved … Try to integrate tables (create unique identifiers): If you join manholes to cables, half of the cable records disappear Model Building Often predictive modeling, meaning machine learning or statistical modeling. If you want to answer a yes/no question, this is classificaiton. For manholes, will the manhole explode nect year? Y/N. If you want to predict a numerical value, this is regression. If you want to group observations into similar-looking groups, this is clustering. If you want to recommend someone an item (e.g. book/ movie/ product) based on ratings data from customers, this is a recommender system. Note: There are many other machine learning problems. Policy Construction How will your model be used to change policy? For manholes, how should we recommend changing the inspection policy based on our model? Consider using social media and customer purchase data to determine customer participation if Starbucks moves into New City. After the model is created, how to optimize where the shops are located, how big they are, and where the warehouses are located. Model building is predictive, Policy Construction is prescriptive. Evaluation How do you measure the quality of the result? Evaluation can be difficult if the data do not provide ground truth. For manhole events, we had engineers at Con Edison withhold high quality recent data and conduct a blind test. Deployment Getting a working proof of concept deployed stops 95% percent of projects. Don’t bother doing the project in the first place if no one plans to deploy it. ( Unless it’s fun.) Keep a realistic timeline in mind. Then add several months. While the model is deployed it will need to be updated and improved. Summary Several attempts to make the process of discovering knowledge scientific KDD, CRISP-DM, CCC Big Data Pipeline All have very similar steps Data Mining is only one of those steps (but an important one) 1.1 Overview of Machine Learning with K-Means Classifiers "],
["exploring-data.html", "2 Exploring Data", " 2 Exploring Data "],
["cleaning-and-preparing-data.html", "3 Cleaning and Preparing Data", " 3 Cleaning and Preparing Data "],
["getting-started-with-supervised-learning.html", "4 Getting Started with Supervised Learning", " 4 Getting Started with Supervised Learning "],
["improving-model-performance.html", "5 Improving Model Performance", " 5 Improving Model Performance "],
["machine-learning-algorithms.html", "6 Machine Learning Algorithms", " 6 Machine Learning Algorithms "],
["unsupervised-learning.html", "7 Unsupervised Learning", " 7 Unsupervised Learning "]
]
