[
["introduction-to-machine-learning.html", "1 Introduction to Machine Learning High Level Data Science Process 1.1 Overview of Machine Learning with K-Means Classifiers", " 1 Introduction to Machine Learning High Level Data Science Process Overview Historical Notes on KDD, CRISP-DM, Big Data and Data Science and their relationship to Data Mining and Machine Learning Example of the knowledge discovery process Historical Note Term “Big Data” coined by astronomers Cox and Ellsworth in 1997 KDD (Knowledge Discovery in Databases) Process Figure 1.1: Based on content in From Data Mining to Knowledge Discovery Cross Industry Standard Process for Data Mining (CRISP-DM) The stages are basically the same no matter who invents or reinvents the (Knowledge discovery / data mining /big data / data science) process. You may not always need all the stages. Data science is an iterative process. - Backwards arrows on most process diagrams. 1.0.1 Example of the knowledge discovery process I’ll walk you through the knowledge discovery process with an example - the process of predicting power failures in Manhattan. Motivation for Example In NYC the peak demand for electricity is rising. The infrastructure dates back to the 1880’s from the time of Thomas Edison. Power failures occur fairly often (enough to do statistic) and are expensive to repair We want to determine how to prioritize manhole inspections in order to reduce the number of manhole events (fires, explosions, outages) in the future. This is a real problem. Stagse in the knowledge discovery procss Opportunity Assessment &amp; Business Understanding Data Understanding &amp; Data Acquisition Data Preparation, including Cleaning and Transformation Model Building Policy Construciton Evaluation, Residuals and Metrics Model Deployment, Monitoring, Model Updates Opportunity Assessment &amp; Business Understanding What do you really want to accomplish and what are the constraints? What are the risks? How will you evaluate the quality of the results? For manhole events the general goal was to “Predict manhole fires and explosions before they occur.” We made it ore precise: Goal 1: Assess predictive accuracy for predicting manhole events in the uear before they happen. Goal 2: Create a cost-benefit analysis for inspection policies that takes into account the cost of inspections and manhole fires. Determine how often manholes need to be inspected. Data Understanding &amp; Data Acquisition Data were: Trouble tickets - free text documents typed by dispatchers documenting problems on the electrical grid. Records of information about manholes Records of information about underground cables Electrical shock information tables Extra information about serious events Inspection reports Vented cover data Data Preparation, including Cleaning and Transformation Sometimes 99% of the work. Turn free text into sturctured information: Trouble tickets turned into a vector like: Serious / Less Serious / Not an Event Year Month Day Manholes involved … Try to integrate tables (create unique identifiers): If you join manholes to cables, half of the cable records disappear Model Building Often predictive modeling, meaning machine learning or statistical modeling. If you want to answer a yes/no question, this is classificaiton. For manholes, will the manhole explode nect year? Y/N. If you want to predict a numerical value, this is regression. If you want to group observations into similar-looking groups, this is clustering. If you want to recommend someone an item (e.g. book/ movie/ product) based on ratings data from customers, this is a recommender system. Note: There are many other machine learning problems. Policy Construction How will your model be used to change policy? For manholes, how should we recommend changing the inspection policy based on our model? Consider using social media and customer purchase data to determine customer participation if Starbucks moves into New City. After the model is created, how to optimize where the shops are located, how big they are, and where the warehouses are located. Model building is predictive, Policy Construction is prescriptive. Evaluation How do you measure the quality of the result? Evaluation can be difficult if the data do not provide ground truth. For manhole events, we had engineers at Con Edison withhold high quality recent data and conduct a blind test. Deployment Getting a working proof of concept deployed stops 95% percent of projects. Don’t bother doing the project in the first place if no one plans to deploy it. ( Unless it’s fun.) Keep a realistic timeline in mind. Then add several months. While the model is deployed it will need to be updated and improved. Summary Several attempts to make the process of discovering knowledge scientific KDD, CRISP-DM, CCC Big Data Pipeline All have very similar steps Data Mining is only one of those steps (but an important one) 1.1 Overview of Machine Learning with K-Means Classifiers "]
]
